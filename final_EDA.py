# -*- coding: utf-8 -*-
"""Football3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Iy7Z4w0ux3xJxy0fkxf1Txe9977cXchp
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data=pd.read_csv('final_data2.csv')

from sklearn.impute import KNNImputer
from sklearn.preprocessing import StandardScaler
import pandas as pd

# Select only the relevant features for imputation
impute_features = ['forty', 'height', 'weight']
impute_data = data[impute_features].copy()

# Step 1: Standardize the columns
scaler = StandardScaler()
scaled_data = scaler.fit_transform(impute_data)

# Step 2: KNN imputation on standardized data
imputer = KNNImputer(n_neighbors=5, weights='distance')
imputed_scaled = imputer.fit_transform(scaled_data)

# Step 3: Inverse transform to return to original scale
imputed_original = scaler.inverse_transform(imputed_scaled)

# Step 4: Replace only the 'forty' column in the original DataFrame
data['forty'] = imputed_original[:, 0]

# Strip whitespace, remove commas, and force convert to float
data['total_round_trip_miles'] = (
    data['total_round_trip_miles']
    .astype(str)
    .str.replace(',', '', regex=False)
    .str.strip()
    .astype(float)
)

exclude_cols = ['is_wr', 'next_season_ir', 'season']
final_selected_features = [col for col in data.columns if col not in exclude_cols]

# (Optional) inspect your final features
print("Final selected features ({}):".format(len(final_selected_features)))
print(final_selected_features)

data.groupby('is_wr')[['age_season_start', 'height', 'weight', 'forty']].agg(['mean', 'std'])

# Define demographic features
demo_cols = ['age_season_start', 'height', 'weight', 'forty', 'past_ir_count']

# Prepare numeric data
demo_data = data[demo_cols].apply(pd.to_numeric, errors='coerce')

# Compute correlation matrix
corr_demo = demo_data.corr().round(2)

# Plot heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr_demo, annot=True, cmap='coolwarm', fmt=".2f",
            square=True, linewidths=0.5, cbar_kws={"shrink": 0.75})
plt.title("")
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

import pandas as pd

# Load the data
data = pd.read_csv('final_data2.csv')

# Count how many rows have next_season_ir == 1
count_ir_1 = (data['next_season_ir'] == 1).sum()

print(f"Number of examples with next_season_ir == 1: {count_ir_1}")

import pandas as pd
from IPython.display import display

# Set pandas display options to show all columns and wider content
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.width', 0)  # Let pandas automatically determine width
pd.set_option('display.max_colwidth', None)

# Ensure your target column is in the DataFrame
assert 'next_season_ir' in data.columns

# Filter the final selected features to numeric only (in case any are non-numeric)
final_numeric_features = data[final_selected_features].select_dtypes(include='number').columns.tolist()

# Group by 'next_season_ir' and compute mean & std for each numeric feature
stats = data.groupby('next_season_ir')[final_numeric_features].agg(['mean', 'std'])

# Display the full result
display(stats)

import numpy as np
import pandas as pd
from scipy.stats import shapiro
from IPython.display import display

# Filter to numeric features only from the final selected set
final_numeric_features = data[final_selected_features].select_dtypes(include='number').columns.tolist()

# Perform Shapiro-Wilk normality test for each numeric feature
print("ðŸ“Š Shapiro-Wilk Normality Test (Raw Values):\n")
normality_results = []

for col in final_numeric_features:
    col_data = data[col].dropna()
    if len(col_data) < 3:
        continue
    stat, p = shapiro(col_data)
    normality_results.append((col, p))
    print(f"{col}: p = {p:.4f} {'âœ… Normal' if p > 0.05 else 'âŒ Non-normal'}")

# Summary DataFrame
normality_df = pd.DataFrame(normality_results, columns=['Feature', 'Shapiro_p'])
normality_df['Normal'] = normality_df['Shapiro_p'] > 0.05
normality_df = normality_df.sort_values('Shapiro_p')

print("\nðŸ“‹ Summary Table:")
display(normality_df)

from scipy.stats import mannwhitneyu
import pandas as pd
from IPython.display import display

# Filter numeric columns from your final selected features
final_numeric_features = data[final_selected_features].select_dtypes(include='number').columns.tolist()

# Separate groups by next_season_ir
group0 = data[data['next_season_ir'] == 0]
group1 = data[data['next_season_ir'] == 1]

# Perform Mann-Whitney U test on each numeric feature
results = []

print("ðŸ“Š Mann-Whitney U Test Results:\n")
for col in final_numeric_features:
    x = pd.to_numeric(group0[col], errors='coerce').dropna()
    y = pd.to_numeric(group1[col], errors='coerce').dropna()
    if len(x) > 5 and len(y) > 5:
        stat, p = mannwhitneyu(x, y, alternative='two-sided')
        results.append((col, p))
        print(f"{col}: p = {p:.4f} {'âœ… Significant' if p < 0.05 else 'â€“ Not significant'}")

# Format into DataFrame
results_df = pd.DataFrame(results, columns=['Feature', 'p_value'])
results_df['Significant'] = results_df['p_value'] < 0.05
results_df = results_df.sort_values('p_value')

print("\nðŸ“‹ Summary Table:")
display(results_df)

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Define significant features from your test
significant_features = ['avgSeparation', 'avg_opponent_pass_epa']

# Generate violin plots for each
for col in significant_features:
    sns.violinplot(
        x='next_season_ir',
        y=pd.to_numeric(data[col], errors='coerce'),
        data=data
    )
    plt.title(f'Violin Plot of {col} by IR Status')
    plt.xlabel('Next Season IR')
    plt.ylabel(col)
    plt.grid(True, linestyle='--', alpha=0.3)
    plt.show()

